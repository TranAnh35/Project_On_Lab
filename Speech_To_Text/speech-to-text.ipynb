{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-12-03T04:02:50.742255Z",
     "iopub.status.busy": "2024-12-03T04:02:50.741929Z",
     "iopub.status.idle": "2024-12-03T04:04:13.347969Z",
     "shell.execute_reply": "2024-12-03T04:04:13.346879Z",
     "shell.execute_reply.started": "2024-12-03T04:02:50.742226Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install evaluate\n",
    "!pip install jiwer\n",
    "!pip install openai-whisper\n",
    "!pip install ptflops\n",
    "!pip install fvcore\n",
    "!pip install ipython-autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T04:04:13.350012Z",
     "iopub.status.busy": "2024-12-03T04:04:13.349724Z",
     "iopub.status.idle": "2024-12-03T04:04:13.358417Z",
     "shell.execute_reply": "2024-12-03T04:04:13.357727Z",
     "shell.execute_reply.started": "2024-12-03T04:04:13.349986Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 114 µs (started: 2024-12-03 04:04:13 +00:00)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T04:04:18.530454Z",
     "iopub.status.busy": "2024-12-03T04:04:18.530120Z",
     "iopub.status.idle": "2024-12-03T04:04:38.197674Z",
     "shell.execute_reply": "2024-12-03T04:04:38.196693Z",
     "shell.execute_reply.started": "2024-12-03T04:04:18.530426Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.7 s (started: 2024-12-03 04:04:18 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import whisper\n",
    "from ptflops import get_model_complexity_info\n",
    "from datasets import load_dataset, get_dataset_split_names\n",
    "from evaluate import load\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, WhisperForConditionalGeneration, WhisperProcessor\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-12-03T04:04:38.199802Z",
     "iopub.status.busy": "2024-12-03T04:04:38.199274Z",
     "iopub.status.idle": "2024-12-03T04:04:39.366661Z",
     "shell.execute_reply": "2024-12-03T04:04:39.365770Z",
     "shell.execute_reply.started": "2024-12-03T04:04:38.199774Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2791ff4d34e4e29b98973ac4050a62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adea66160d1745639b580179cc85ebc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.60k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.16 s (started: 2024-12-03 04:04:38 +00:00)\n"
     ]
    }
   ],
   "source": [
    "wer = load(\"wer\")\n",
    "cer = load(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-12-03T04:04:39.367821Z",
     "iopub.status.busy": "2024-12-03T04:04:39.367587Z",
     "iopub.status.idle": "2024-12-03T04:04:54.772318Z",
     "shell.execute_reply": "2024-12-03T04:04:54.771488Z",
     "shell.execute_reply.started": "2024-12-03T04:04:39.367799Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9897b80e663545bda606ab0b279f4973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "common_voice_11_0.py:   0%|          | 0.00/8.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "186b2e76a61e4894bbd55e89005a767a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/14.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15099446f26c423fa759ba9ca430ab3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "languages.py:   0%|          | 0.00/3.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc89f60544af416ea2bb9b8992b86269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "release_stats.py:   0%|          | 0.00/60.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e492e84beb3043d7a9eaef767df2fae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "n_shards.json:   0%|          | 0.00/12.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1ce2cc64ec4703b5d6a6606448c42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vi_train_0.tar:   0%|          | 0.00/76.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c4e76eca334ff297e66660b2245a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vi_dev_0.tar:   0%|          | 0.00/5.54M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580e9a37407941299d7f2777812bcdd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vi_test_0.tar:   0%|          | 0.00/33.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a17be60e64491eb72fd8b39ee3b19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vi_other_0.tar:   0%|          | 0.00/274M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24968704f354e439d5d3241b68cd0ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vi_invalidated_0.tar:   0%|          | 0.00/10.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d89e5cf4174a43b5323ed3507d9345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.tsv:   0%|          | 0.00/562k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c653733f0824b0d8383c90f580af4bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dev.tsv:   0%|          | 0.00/53.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325d81961b724a38a45bb38deac7a730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.tsv:   0%|          | 0.00/272k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6a3dce16e940ebbe802a6d56e9bf56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "other.tsv:   0%|          | 0.00/2.52M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1277dc2d6b406eab53569ad8a01cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "invalidated.tsv:   0%|          | 0.00/74.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a4e720eefa4f5b82ac94c1bd16758a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading metadata...: 2525it [00:00, 133868.66it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f030c349033148b2a2258a19dfa23cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading metadata...: 248it [00:00, 94493.77it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1172ffcfb34060901660eba09acdce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading metadata...: 1237it [00:00, 87670.73it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13691b67461946f6b9b55f78b412360b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating other split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading metadata...: 11476it [00:00, 154233.58it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7564b1b11ce74c44872339ed42bd3d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating invalidated split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading metadata...: 337it [00:00, 128943.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.4 s (started: 2024-12-03 04:04:39 +00:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vi_dataset = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"vi\", split=\"test\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T05:39:44.562290Z",
     "iopub.status.busy": "2024-12-03T05:39:44.561889Z",
     "iopub.status.idle": "2024-12-03T05:39:44.572024Z",
     "shell.execute_reply": "2024-12-03T05:39:44.571122Z",
     "shell.execute_reply.started": "2024-12-03T05:39:44.562243Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.11 ms (started: 2024-12-03 05:39:44 +00:00)\n"
     ]
    }
   ],
   "source": [
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“]'\n",
    "resampler = torchaudio.transforms.Resample(48_000, 16_000)\n",
    "\n",
    "def speech_file_to_array_fn(batch):\n",
    "    batch[\"sentence\"] = re.sub(chars_to_ignore_regex, '', batch[\"sentence\"]).lower()\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "    batch[\"speech\"] = resampler(speech_array).squeeze().numpy()\n",
    "    return batch\n",
    "\n",
    "def evaluate(batch):\n",
    "    inputs = processor(batch[\"speech\"], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs.input_values.to(\"cuda\"), attention_mask=inputs.attention_mask.to(\"cuda\")).logits\n",
    "\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    batch[\"pred_strings\"] = processor.batch_decode(pred_ids)\n",
    "\n",
    "    return batch\n",
    "\n",
    "def reset_memory_stats():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def print_memory_usage_summary():\n",
    "    max_allocated = torch.cuda.max_memory_allocated() / (1024**2)\n",
    "    max_reserved = torch.cuda.max_memory_reserved() / (1024**2)\n",
    "    print(f\"Peak memory allocated: {max_allocated:.2f} MB\")\n",
    "    print(f\"Peak memory reserved: {max_reserved:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vietnamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T04:05:36.977776Z",
     "iopub.status.busy": "2024-12-03T04:05:36.977206Z",
     "iopub.status.idle": "2024-12-03T04:05:44.941875Z",
     "shell.execute_reply": "2024-12-03T04:05:44.940684Z",
     "shell.execute_reply.started": "2024-12-03T04:05:36.977744Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5ef6a02e7945468bf97d74d400a031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1237 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.96 s (started: 2024-12-03 04:05:36 +00:00)\n"
     ]
    }
   ],
   "source": [
    "vi_dataset = vi_dataset.map(speech_file_to_array_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T04:05:47.624773Z",
     "iopub.status.busy": "2024-12-03T04:05:47.624412Z",
     "iopub.status.idle": "2024-12-03T04:05:47.632011Z",
     "shell.execute_reply": "2024-12-03T04:05:47.631119Z",
     "shell.execute_reply.started": "2024-12-03T04:05:47.624741Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment', 'speech'],\n",
       "    num_rows: 1237\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.46 ms (started: 2024-12-03 04:05:47 +00:00)\n"
     ]
    }
   ],
   "source": [
    "vi_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T04:05:49.302240Z",
     "iopub.status.busy": "2024-12-03T04:05:49.301883Z",
     "iopub.status.idle": "2024-12-03T04:05:49.310512Z",
     "shell.execute_reply": "2024-12-03T04:05:49.309672Z",
     "shell.execute_reply.started": "2024-12-03T04:05:49.302210Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hương thu còn thoảng đâu đây bên thềm'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.54 ms (started: 2024-12-03 04:05:49 +00:00)\n"
     ]
    }
   ],
   "source": [
    "vi_dataset[\"sentence\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wav2Vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T04:05:51.346757Z",
     "iopub.status.busy": "2024-12-03T04:05:51.346406Z",
     "iopub.status.idle": "2024-12-03T04:07:10.867731Z",
     "shell.execute_reply": "2024-12-03T04:07:10.866910Z",
     "shell.execute_reply.started": "2024-12-03T04:05:51.346729Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec46982c84c4bf5afda5fef04e21a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/158 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7528e0d5ae1c42b8b70b8de4abee4f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b264951ddd460ea31caa307f3aff97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py:302: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e051e2fee3e404fa6affe815188f96c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/938 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a73e69ca8044379b9b2d06fc8adf15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74fbcfc9d5c4e7ea59c98dd5d0e7fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.26G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function evaluate at 0x7843e8422050> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a80276f34dd45e99ec9305245bcadbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1237 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak memory allocated: 2729.54 MB\n",
      "Peak memory reserved: 7568.00 MB\n",
      "CER: 29.543150\n",
      "time: 1min 19s (started: 2024-12-03 04:05:51 +00:00)\n"
     ]
    }
   ],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(\"CuongLD/wav2vec2-large-xlsr-vietnamese\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"CuongLD/wav2vec2-large-xlsr-vietnamese\")\n",
    "model.to(\"cuda\")\n",
    "\n",
    "reset_memory_stats()\n",
    "\n",
    "result = vi_dataset.map(evaluate, batched=True, batch_size=8)\n",
    "\n",
    "print_memory_usage_summary()\n",
    "\n",
    "print(\"CER: {:2f}\".format(100 * cer.compute(predictions=result[\"pred_strings\"], references=result[\"sentence\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T04:13:25.353286Z",
     "iopub.status.busy": "2024-12-03T04:13:25.352928Z",
     "iopub.status.idle": "2024-12-03T04:13:25.359441Z",
     "shell.execute_reply": "2024-12-03T04:13:25.358509Z",
     "shell.execute_reply.started": "2024-12-03T04:13:25.353257Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 641 µs (started: 2024-12-03 04:13:25 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def evaluate(batch):\n",
    "    audio_tensor = torch.tensor(batch[\"speech\"], dtype=torch.float32)\n",
    "    audio_tensor = audio_tensor / torch.max(torch.abs(audio_tensor))\n",
    "\n",
    "    result = model.transcribe(audio_tensor.numpy(), language=\"vi\")\n",
    "    batch[\"pred_strings\"] = result[\"text\"]\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T04:13:27.246569Z",
     "iopub.status.busy": "2024-12-03T04:13:27.246200Z",
     "iopub.status.idle": "2024-12-03T04:30:55.291323Z",
     "shell.execute_reply": "2024-12-03T04:30:55.290450Z",
     "shell.execute_reply.started": "2024-12-03T04:13:27.246538Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271e4194bd15403c9590b4585b1faeb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1237 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak memory allocated: 6912.28 MB\n",
      "Peak memory reserved: 11026.00 MB\n",
      "CER: 22.431553\n",
      "time: 17min 28s (started: 2024-12-03 04:13:27 +00:00)\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"medium\")\n",
    "model.to(\"cuda\")\n",
    "\n",
    "reset_memory_stats()\n",
    "\n",
    "result = vi_dataset.map(evaluate, batched=False)\n",
    "\n",
    "print_memory_usage_summary()\n",
    "\n",
    "print(\"CER: {:2f}\".format(100 * cer.compute(predictions=result[\"pred_strings\"], references=result[\"sentence\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T04:43:26.185121Z",
     "iopub.status.busy": "2024-12-03T04:43:26.184111Z",
     "iopub.status.idle": "2024-12-03T04:53:53.422693Z",
     "shell.execute_reply": "2024-12-03T04:53:53.421884Z",
     "shell.execute_reply.started": "2024-12-03T04:43:26.185069Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 461M/461M [00:05<00:00, 94.5MiB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0047dce3aca4d6db3efc0c2c27a3647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1237 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak memory allocated: 1073.89 MB\n",
      "Peak memory reserved: 7062.00 MB\n",
      "CER: 28.948071\n",
      "time: 10min 27s (started: 2024-12-03 04:43:26 +00:00)\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"small\")\n",
    "model.to(\"cuda\")\n",
    "\n",
    "reset_memory_stats()\n",
    "\n",
    "result = vi_dataset.map(evaluate, batched=False)\n",
    "\n",
    "print_memory_usage_summary()\n",
    "\n",
    "print(\"CER: {:2f}\".format(100 * cer.compute(predictions=result[\"pred_strings\"], references=result[\"sentence\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T04:54:14.384319Z",
     "iopub.status.busy": "2024-12-03T04:54:14.383684Z",
     "iopub.status.idle": "2024-12-03T05:04:28.293469Z",
     "shell.execute_reply": "2024-12-03T05:04:28.292583Z",
     "shell.execute_reply.started": "2024-12-03T04:54:14.384279Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 139M/139M [00:01<00:00, 88.1MiB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b5b5f07ce64353957516014892bae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1237 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak memory allocated: 361.58 MB\n",
      "Peak memory reserved: 1464.00 MB\n",
      "CER: 50.971340\n",
      "time: 10min 13s (started: 2024-12-03 04:54:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"base\")\n",
    "model.to(\"cuda\")\n",
    "\n",
    "reset_memory_stats()\n",
    "\n",
    "result = vi_dataset.map(evaluate, batched=False)\n",
    "\n",
    "print_memory_usage_summary()\n",
    "\n",
    "print(\"CER: {:2f}\".format(100 * cer.compute(predictions=result[\"pred_strings\"], references=result[\"sentence\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T05:04:28.295125Z",
     "iopub.status.busy": "2024-12-03T05:04:28.294822Z",
     "iopub.status.idle": "2024-12-03T05:17:21.124032Z",
     "shell.execute_reply": "2024-12-03T05:17:21.123195Z",
     "shell.execute_reply.started": "2024-12-03T05:04:28.295098Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 72.1M/72.1M [00:02<00:00, 31.0MiB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ad6ca48b424979b5983a7a4a7f0309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1237 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak memory allocated: 204.56 MB\n",
      "Peak memory reserved: 760.00 MB\n",
      "CER: 67.235950\n",
      "time: 12min 52s (started: 2024-12-03 05:04:28 +00:00)\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"tiny\")\n",
    "model.to(\"cuda\")\n",
    "\n",
    "reset_memory_stats()\n",
    "\n",
    "result = vi_dataset.map(evaluate, batched=False)\n",
    "\n",
    "print_memory_usage_summary()\n",
    "\n",
    "print(\"CER: {:2f}\".format(100 * cer.compute(predictions=result[\"pred_strings\"], references=result[\"sentence\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T05:39:55.922927Z",
     "iopub.status.busy": "2024-12-03T05:39:55.922560Z",
     "iopub.status.idle": "2024-12-03T05:39:55.939316Z",
     "shell.execute_reply": "2024-12-03T05:39:55.938262Z",
     "shell.execute_reply.started": "2024-12-03T05:39:55.922894Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.6 ms (started: 2024-12-03 05:39:55 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "en_dataset_path = \"/kaggle/input/common-voice\"\n",
    "csv_file = os.path.join(en_dataset_path, \"cv-valid-test.csv\")\n",
    "\n",
    "data = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T05:39:56.952740Z",
     "iopub.status.busy": "2024-12-03T05:39:56.952351Z",
     "iopub.status.idle": "2024-12-03T05:39:56.959470Z",
     "shell.execute_reply": "2024-12-03T05:39:56.958540Z",
     "shell.execute_reply.started": "2024-12-03T05:39:56.952711Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'text', 'up_votes', 'down_votes', 'age', 'gender', 'accent',\n",
       "       'duration'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.11 ms (started: 2024-12-03 05:39:56 +00:00)\n"
     ]
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T05:39:57.789218Z",
     "iopub.status.busy": "2024-12-03T05:39:57.788399Z",
     "iopub.status.idle": "2024-12-03T05:39:57.800152Z",
     "shell.execute_reply": "2024-12-03T05:39:57.799327Z",
     "shell.execute_reply.started": "2024-12-03T05:39:57.789180Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv-valid-test/sample-000000.mp3</td>\n",
       "      <td>without the dataset the article is useless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv-valid-test/sample-000001.mp3</td>\n",
       "      <td>i've got to go to him</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv-valid-test/sample-000002.mp3</td>\n",
       "      <td>and you know it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cv-valid-test/sample-000003.mp3</td>\n",
       "      <td>down below in the darkness were hundreds of pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cv-valid-test/sample-000004.mp3</td>\n",
       "      <td>hold your nose to keep the smell from disablin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>cv-valid-test/sample-000495.mp3</td>\n",
       "      <td>since the miner had sacrificed everything to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>cv-valid-test/sample-000496.mp3</td>\n",
       "      <td>i would have won the junior olympics if not fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>cv-valid-test/sample-000497.mp3</td>\n",
       "      <td>i've got indigestion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>cv-valid-test/sample-000498.mp3</td>\n",
       "      <td>he is going to transform himself into the wind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>cv-valid-test/sample-000499.mp3</td>\n",
       "      <td>it's going to take a while the boy said</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            filename  \\\n",
       "0    cv-valid-test/sample-000000.mp3   \n",
       "1    cv-valid-test/sample-000001.mp3   \n",
       "2    cv-valid-test/sample-000002.mp3   \n",
       "3    cv-valid-test/sample-000003.mp3   \n",
       "4    cv-valid-test/sample-000004.mp3   \n",
       "..                               ...   \n",
       "495  cv-valid-test/sample-000495.mp3   \n",
       "496  cv-valid-test/sample-000496.mp3   \n",
       "497  cv-valid-test/sample-000497.mp3   \n",
       "498  cv-valid-test/sample-000498.mp3   \n",
       "499  cv-valid-test/sample-000499.mp3   \n",
       "\n",
       "                                                  text  \n",
       "0           without the dataset the article is useless  \n",
       "1                                i've got to go to him  \n",
       "2                                      and you know it  \n",
       "3    down below in the darkness were hundreds of pe...  \n",
       "4    hold your nose to keep the smell from disablin...  \n",
       "..                                                 ...  \n",
       "495  since the miner had sacrificed everything to h...  \n",
       "496  i would have won the junior olympics if not fo...  \n",
       "497                               i've got indigestion  \n",
       "498  he is going to transform himself into the wind...  \n",
       "499            it's going to take a while the boy said  \n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.09 ms (started: 2024-12-03 05:39:57 +00:00)\n"
     ]
    }
   ],
   "source": [
    "data = data.iloc[:500, :2]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T05:39:58.831722Z",
     "iopub.status.busy": "2024-12-03T05:39:58.830815Z",
     "iopub.status.idle": "2024-12-03T05:39:58.837910Z",
     "shell.execute_reply": "2024-12-03T05:39:58.836910Z",
     "shell.execute_reply.started": "2024-12-03T05:39:58.831684Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.89 ms (started: 2024-12-03 05:39:58 +00:00)\n"
     ]
    }
   ],
   "source": [
    "base_path = \"/kaggle/input/common-voice/cv-valid-test/\"\n",
    "\n",
    "data[\"filename\"] = data[\"filename\"].apply(lambda x: os.path.join(base_path, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T05:39:59.664913Z",
     "iopub.status.busy": "2024-12-03T05:39:59.664258Z",
     "iopub.status.idle": "2024-12-03T05:39:59.672012Z",
     "shell.execute_reply": "2024-12-03T05:39:59.671094Z",
     "shell.execute_reply.started": "2024-12-03T05:39:59.664870Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename    /kaggle/input/common-voice/cv-valid-test/cv-va...\n",
       "text               without the dataset the article is useless\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.31 ms (started: 2024-12-03 05:39:59 +00:00)\n"
     ]
    }
   ],
   "source": [
    "data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T05:43:03.226812Z",
     "iopub.status.busy": "2024-12-03T05:43:03.225883Z",
     "iopub.status.idle": "2024-12-03T05:43:03.232098Z",
     "shell.execute_reply": "2024-12-03T05:43:03.231142Z",
     "shell.execute_reply.started": "2024-12-03T05:43:03.226772Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 628 µs (started: 2024-12-03 05:43:03 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def speech_file_to_array_fn(batch):\n",
    "    # Làm sạch nội dung text, bỏ các ký tự không cần thiết và chuyển về chữ thường\n",
    "    batch[\"text\"] = re.sub(chars_to_ignore_regex, '', batch[\"text\"]).upper()\n",
    "    \n",
    "    # Load file âm thanh và resample nếu cần\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"filename\"])\n",
    "    batch[\"speech\"] = resampler(speech_array).squeeze().numpy()\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T05:43:07.543936Z",
     "iopub.status.busy": "2024-12-03T05:43:07.543079Z",
     "iopub.status.idle": "2024-12-03T05:43:12.087036Z",
     "shell.execute_reply": "2024-12-03T05:43:12.086076Z",
     "shell.execute_reply.started": "2024-12-03T05:43:07.543884Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4b6887dbae4fb9828fb28e95592ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.54 s (started: 2024-12-03 05:43:07 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "en_dataset = Dataset.from_pandas(data)\n",
    "\n",
    "en_dataset = en_dataset.map(speech_file_to_array_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T05:43:12.088748Z",
     "iopub.status.busy": "2024-12-03T05:43:12.088475Z",
     "iopub.status.idle": "2024-12-03T05:43:12.094884Z",
     "shell.execute_reply": "2024-12-03T05:43:12.093984Z",
     "shell.execute_reply.started": "2024-12-03T05:43:12.088722Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['filename', 'text', 'speech'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.62 ms (started: 2024-12-03 05:43:12 +00:00)\n"
     ]
    }
   ],
   "source": [
    "en_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wev2Vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T05:43:12.096273Z",
     "iopub.status.busy": "2024-12-03T05:43:12.096014Z",
     "iopub.status.idle": "2024-12-03T05:43:55.706023Z",
     "shell.execute_reply": "2024-12-03T05:43:55.705220Z",
     "shell.execute_reply.started": "2024-12-03T05:43:12.096249Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h-lv60-self and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9b3a3b994143439a4a5f7bb542ae99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak memory allocated: 3046.29 MB\n",
      "Peak memory reserved: 10402.00 MB\n",
      "WER: 6.505657\n",
      "time: 43.6 s (started: 2024-12-03 05:43:12 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModelForCTC\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")\n",
    "model = AutoModelForCTC.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\")\n",
    "model.to(\"cuda\")\n",
    "\n",
    "reset_memory_stats()\n",
    "\n",
    "result = en_dataset.map(evaluate, batched=True, batch_size=8)\n",
    "\n",
    "print_memory_usage_summary()\n",
    "\n",
    "print(\"WER: {:2f}\".format(100 * wer.compute(predictions=result[\"pred_strings\"], references=result[\"text\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T05:43:55.708574Z",
     "iopub.status.busy": "2024-12-03T05:43:55.707971Z",
     "iopub.status.idle": "2024-12-03T05:43:55.714246Z",
     "shell.execute_reply": "2024-12-03T05:43:55.713434Z",
     "shell.execute_reply.started": "2024-12-03T05:43:55.708531Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITHOUT THE DATA SET THE ARTECLE IS USELESS\n",
      "WITHOUT THE DATASET THE ARTICLE IS USELESS\n",
      "time: 1.76 ms (started: 2024-12-03 05:43:55 +00:00)\n"
     ]
    }
   ],
   "source": [
    "print(result[\"pred_strings\"][0])\n",
    "print(result[\"text\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T07:05:31.523998Z",
     "iopub.status.busy": "2024-12-03T07:05:31.522996Z",
     "iopub.status.idle": "2024-12-03T07:05:31.529954Z",
     "shell.execute_reply": "2024-12-03T07:05:31.528922Z",
     "shell.execute_reply.started": "2024-12-03T07:05:31.523947Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 787 µs (started: 2024-12-03 07:05:31 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def evaluate(batch):\n",
    "    audio_tensor = torch.tensor(batch[\"speech\"], dtype=torch.float32)\n",
    "    audio_tensor = audio_tensor / torch.max(torch.abs(audio_tensor))\n",
    "\n",
    "    result = model.transcribe(audio_tensor.numpy(), language=\"en\")\n",
    "    batch[\"pred_strings\"] = result[\"text\"]\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T07:34:47.723708Z",
     "iopub.status.busy": "2024-12-03T07:34:47.723322Z",
     "iopub.status.idle": "2024-12-03T07:40:40.501120Z",
     "shell.execute_reply": "2024-12-03T07:40:40.500309Z",
     "shell.execute_reply.started": "2024-12-03T07:34:47.723674Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805d3a08024344f98172c968e57c1eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak memory allocated: 3171.91 MB\n",
      "Peak memory reserved: 7300.00 MB\n",
      "WER: 4.503916\n",
      "time: 5min 52s (started: 2024-12-03 07:34:47 +00:00)\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"medium\")\n",
    "model.to(\"cuda\")\n",
    "\n",
    "reset_memory_stats()\n",
    "\n",
    "result = en_dataset.map(evaluate, batched=False)\n",
    "\n",
    "print_memory_usage_summary()\n",
    "\n",
    "predictions_cleaned = [\n",
    "    re.sub(chars_to_ignore_regex, '', ''.join(pred).upper()) for pred in result[\"pred_strings\"]\n",
    "]\n",
    "print(\"WER: {:2f}\".format(100 * wer.compute(predictions=predictions_cleaned, references=result[\"text\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T08:09:03.330665Z",
     "iopub.status.busy": "2024-12-03T08:09:03.330189Z",
     "iopub.status.idle": "2024-12-03T08:09:03.336273Z",
     "shell.execute_reply": "2024-12-03T08:09:03.335385Z",
     "shell.execute_reply.started": "2024-12-03T08:09:03.330629Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " WITHOUT THE DATA SET THE ARTICLE IS USELESS\n",
      "WITHOUT THE DATASET THE ARTICLE IS USELESS\n",
      "time: 1.3 ms (started: 2024-12-03 08:09:03 +00:00)\n"
     ]
    }
   ],
   "source": [
    "print(predictions_cleaned[0])\n",
    "print(result[\"text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T08:16:28.207245Z",
     "iopub.status.busy": "2024-12-03T08:16:28.206275Z",
     "iopub.status.idle": "2024-12-03T08:19:26.488424Z",
     "shell.execute_reply": "2024-12-03T08:19:26.487401Z",
     "shell.execute_reply.started": "2024-12-03T08:16:28.207206Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc88380a8f194b30a14f85a0c2b67af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak memory allocated: 1067.56 MB\n",
      "Peak memory reserved: 2452.00 MB\n",
      "WER: 6.201044\n",
      "time: 2min 58s (started: 2024-12-03 08:16:28 +00:00)\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"small\")\n",
    "model.to(\"cuda\")\n",
    "\n",
    "reset_memory_stats()\n",
    "\n",
    "result = en_dataset.map(evaluate, batched=False)\n",
    "\n",
    "print_memory_usage_summary()\n",
    "\n",
    "predictions_cleaned = [\n",
    "    re.sub(chars_to_ignore_regex, '', ''.join(pred).upper()) for pred in result[\"pred_strings\"]\n",
    "]\n",
    "print(\"WER: {:2f}\".format(100 * wer.compute(predictions=predictions_cleaned, references=result[\"text\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T08:19:26.490786Z",
     "iopub.status.busy": "2024-12-03T08:19:26.490419Z",
     "iopub.status.idle": "2024-12-03T08:21:07.435878Z",
     "shell.execute_reply": "2024-12-03T08:21:07.435028Z",
     "shell.execute_reply.started": "2024-12-03T08:19:26.490748Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b285e966854f9095355cdaa2fcee26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak memory allocated: 366.03 MB\n",
      "Peak memory reserved: 1408.00 MB\n",
      "WER: 9.551784\n",
      "time: 1min 40s (started: 2024-12-03 08:19:26 +00:00)\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"base\")\n",
    "model.to(\"cuda\")\n",
    "\n",
    "reset_memory_stats()\n",
    "\n",
    "result = en_dataset.map(evaluate, batched=False)\n",
    "\n",
    "print_memory_usage_summary()\n",
    "\n",
    "predictions_cleaned = [\n",
    "    re.sub(chars_to_ignore_regex, '', ''.join(pred).upper()) for pred in result[\"pred_strings\"]\n",
    "]\n",
    "print(\"WER: {:2f}\".format(100 * wer.compute(predictions=predictions_cleaned, references=result[\"text\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T08:21:07.437369Z",
     "iopub.status.busy": "2024-12-03T08:21:07.437023Z",
     "iopub.status.idle": "2024-12-03T08:22:28.739677Z",
     "shell.execute_reply": "2024-12-03T08:22:28.738574Z",
     "shell.execute_reply.started": "2024-12-03T08:21:07.437330Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc59eff9a97462ebfd392eda0002e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak memory allocated: 209.00 MB\n",
      "Peak memory reserved: 520.00 MB\n",
      "WER: 15.752829\n",
      "time: 1min 21s (started: 2024-12-03 08:21:07 +00:00)\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"tiny\")\n",
    "model.to(\"cuda\")\n",
    "\n",
    "reset_memory_stats()\n",
    "\n",
    "result = en_dataset.map(evaluate, batched=False)\n",
    "\n",
    "print_memory_usage_summary()\n",
    "\n",
    "predictions_cleaned = [\n",
    "    re.sub(chars_to_ignore_regex, '', ''.join(pred).upper()) for pred in result[\"pred_strings\"]\n",
    "]\n",
    "print(\"WER: {:2f}\".format(100 * wer.compute(predictions=predictions_cleaned, references=result[\"text\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5793,
     "sourceId": 9812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
